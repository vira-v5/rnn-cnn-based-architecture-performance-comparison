{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, Adagrad\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"new_complaints3.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data splited into feature and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df['new']\n",
    "y_data = df['Product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         transworld systems inc \\nis trying to collect ...\n",
       "1         Over the past 2 weeks I have been receiving ex...\n",
       "2         Pioneer has committed several federal violatio...\n",
       "3         Previously on XX XX XXXX XX XX XXXX and XX XX ...\n",
       "4         Hello This complaint is against the three cred...\n",
       "                                ...                        \n",
       "597869    1  Mailing Address is incorrect \\n2  Date of B...\n",
       "597870    I made a purchase of ##### on XXXX XXXX #### u...\n",
       "597871    On XXXX XXXX #### I contacted XXXX XXXX who is...\n",
       "597872    I can not get from chase who services my mortg...\n",
       "597873    cfbp i would Like to file a complaint on Exper...\n",
       "Name: new, Length: 597874, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame converted to a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_data.values\n",
    "y = y_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data splitted into train and test set, the train set is 80 percent of the data, and the test set is 20 percent. The data is stratified based on the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_value, X_val_value, y_train_value, y_val_value = train_test_split(X, y, \n",
    "                                                                          test_size=0.4, \n",
    "                                                                          random_state=666, \n",
    "                                                                          stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary was built based on the unique words from the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower=False)\n",
    "tokenizer.fit_on_texts(X_train_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159487"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an empty weight matrix for words in document vocabulary, +1 because the word index dictionary value starting from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size+1, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = KeyedVectors.load('vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = vectors[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        embedding_vector = vectors['UNK']\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train_value)\n",
    "X_val = tokenizer.texts_to_sequences(X_val_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val_value[1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I previously tried to settle this matter with experian about unauthorized inquiries on my consumer report i sent them a letter explaining the problem trying to get experian to resolve the issue but they never did On XX XX #### i sent out another letter certified about the unauthorized inquiries on my consumer report and i still have not got a response I requested there method of verification about these inquires and i never received anything from experian i will send a copy of the certified letter that i sent to experian on XX XX ####'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_value[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequences of words padded and limited to 200 sequences per instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=200, truncating='post', padding='post')\n",
    "X_val = pad_sequences(X_val, maxlen=200, truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label converted to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "y_train_label = enc.fit_transform(y_train_value)\n",
    "y_val_label = enc.transform(y_val_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Checking or savings account' 'Credit card or prepaid card'\n",
      " 'Credit or consumer reporting, credit repair services' 'Debt collection'\n",
      " 'Money transfer or service, virtual currency' 'Mortgage' 'Personal loan'\n",
      " 'Student loan' 'Vehicle loan or lease']\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]), array([ 15516,  38824, 145461,  74649,   7690,  42251,  11619,  16220,\n",
      "         6494], dtype=int64))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]), array([10344, 25882, 96974, 49767,  5126, 28168,  7746, 10813,  4330],\n",
      "      dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(enc.classes_)\n",
    "print(np.unique(y_train_label, return_counts=True))\n",
    "print(np.unique(y_val_label, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (358724, 200)\n",
      "Shape of label tensor: (358724, 9)\n",
      "Shape of label tensor: (239150, 9)\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(np.asarray(y_train_label))\n",
    "y_val = to_categorical(np.asarray(y_val_label))\n",
    "print('Shape of data tensor:', X_train.shape)\n",
    "print('Shape of label tensor:', y_train.shape)\n",
    "print('Shape of label tensor:', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data further for validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=666, stratify=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training/validation/test\n",
      "358724/119575/119575\n"
     ]
    }
   ],
   "source": [
    "print('training/validation/test')\n",
    "print(str(X_train.shape[0]) + '/' + str(X_val.shape[0]) + '/' + str(X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN with no pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dropout, Conv1D, MaxPool1D, Flatten\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = vocab_size + 1\n",
    "output_dim = 300\n",
    "input_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor=\"val_loss\",\n",
    "                              mode=\"min\", patience=5,\n",
    "                              restore_best_weights=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_length=200\n",
    "rnn = Sequential()\n",
    "rnn.add(Embedding(input_dim=input_dim,\n",
    "                            output_dim=output_dim,\n",
    "                            input_length=input_length,\n",
    "                            trainable=True))\n",
    "rnn.add(LSTM(128))\n",
    "rnn.add(Dropout(0.2))\n",
    "rnn.add(Dense(9,activation='softmax'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "rnn.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 300)          47846400  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 48,067,209\n",
      "Trainable params: 48,067,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7175/7175 [==============================] - 6991s 974ms/step - loss: 0.8228 - acc: 0.7225 - val_loss: 0.4704 - val_acc: 0.8429\n",
      "Epoch 2/50\n",
      "7175/7175 [==============================] - 7595s 1s/step - loss: 0.4286 - acc: 0.8562 - val_loss: 0.4379 - val_acc: 0.8508\n",
      "Epoch 3/50\n",
      "7175/7175 [==============================] - 6778s 945ms/step - loss: 0.3497 - acc: 0.8820 - val_loss: 0.4526 - val_acc: 0.8517\n",
      "Epoch 4/50\n",
      "7175/7175 [==============================] - 7476s 1s/step - loss: 0.2827 - acc: 0.9050 - val_loss: 0.4779 - val_acc: 0.8495\n",
      "Epoch 5/50\n",
      "7175/7175 [==============================] - 6816s 950ms/step - loss: 0.2263 - acc: 0.9246 - val_loss: 0.5223 - val_acc: 0.8450\n",
      "Epoch 6/50\n",
      "7175/7175 [==============================] - 7313s 1s/step - loss: 0.1832 - acc: 0.9388 - val_loss: 0.5685 - val_acc: 0.8425\n",
      "Epoch 7/50\n",
      "7175/7175 [==============================] - 6560s 914ms/step - loss: 0.1491 - acc: 0.9506 - val_loss: 0.6476 - val_acc: 0.8377\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "history5 = rnn.fit(X_train, y_train, epochs=50, batch_size=batch_size, verbose=1,  \n",
    "                    validation_data=(X_val, y_val),callbacks =[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping2 = EarlyStopping(monitor=\"val_loss\",\n",
    "                              mode=\"min\", patience=5,\n",
    "                              restore_best_weights=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_length=200\n",
    "cnn = Sequential()\n",
    "cnn.add(Embedding(input_dim=input_dim,\n",
    "                            output_dim=output_dim,\n",
    "                            input_length=input_length,\n",
    "                            trainable=True))\n",
    "cnn.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn.add(Dropout(0.2))\n",
    "#cnn.add(MaxPool1D(5))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(9,activation='softmax'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 200, 300)          47846400  \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 196, 128)          192128    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 196, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 225801    \n",
      "=================================================================\n",
      "Total params: 48,264,329\n",
      "Trainable params: 48,264,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7175/7175 [==============================] - 6327s 882ms/step - loss: 0.5918 - acc: 0.8121 - val_loss: 0.5253 - val_acc: 0.8322\n",
      "Epoch 2/50\n",
      "7175/7175 [==============================] - 6047s 843ms/step - loss: 0.4462 - acc: 0.8585 - val_loss: 0.5578 - val_acc: 0.8318\n",
      "Epoch 3/50\n",
      "7175/7175 [==============================] - 6016s 839ms/step - loss: 0.3423 - acc: 0.8894 - val_loss: 0.6357 - val_acc: 0.8280\n",
      "Epoch 4/50\n",
      "7175/7175 [==============================] - 7572s 1s/step - loss: 0.2611 - acc: 0.9163 - val_loss: 0.7630 - val_acc: 0.8242\n",
      "Epoch 5/50\n",
      "7175/7175 [==============================] - 6316s 880ms/step - loss: 0.2134 - acc: 0.9323 - val_loss: 0.9039 - val_acc: 0.8212\n",
      "Epoch 6/50\n",
      "7175/7175 [==============================] - 6359s 886ms/step - loss: 0.1882 - acc: 0.9415 - val_loss: 1.0457 - val_acc: 0.8198\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "history6 = cnn.fit(X_train, y_train, epochs=50, batch_size=batch_size, verbose=1,  \n",
    "                    validation_data=(X_val, y_val),callbacks =[earlystopping2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping3 = EarlyStopping(monitor=\"val_loss\",\n",
    "                              mode=\"min\", patience=5,\n",
    "                              restore_best_weights=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_length=200\n",
    "cnn2 = Sequential()\n",
    "cnn2.add(Embedding(input_dim=input_dim,\n",
    "                            output_dim=output_dim,\n",
    "                            input_length=input_length,\n",
    "                            trainable=True))\n",
    "cnn2.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn2.add(Dropout(0.2))\n",
    "cnn2.add(MaxPool1D(5))\n",
    "cnn2.add(Flatten())\n",
    "cnn2.add(Dense(9,activation='softmax'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "cnn2.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 200, 300)          47846400  \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 196, 128)          192128    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 196, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4992)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 44937     \n",
      "=================================================================\n",
      "Total params: 48,083,465\n",
      "Trainable params: 48,083,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7175/7175 [==============================] - 5462s 761ms/step - loss: 0.5773 - acc: 0.8157 - val_loss: 0.5215 - val_acc: 0.8358\n",
      "Epoch 2/50\n",
      "7175/7175 [==============================] - 5459s 761ms/step - loss: 0.4386 - acc: 0.8594 - val_loss: 0.5389 - val_acc: 0.8361\n",
      "Epoch 3/50\n",
      "7175/7175 [==============================] - 5462s 761ms/step - loss: 0.3460 - acc: 0.8884 - val_loss: 0.5716 - val_acc: 0.8336\n",
      "Epoch 4/50\n",
      "7175/7175 [==============================] - 5452s 760ms/step - loss: 0.2685 - acc: 0.9130 - val_loss: 0.6627 - val_acc: 0.8263\n",
      "Epoch 5/50\n",
      "7175/7175 [==============================] - 5441s 758ms/step - loss: 0.2165 - acc: 0.9306 - val_loss: 0.7841 - val_acc: 0.8256\n",
      "Epoch 6/50\n",
      "7175/7175 [==============================] - 5678s 791ms/step - loss: 0.1857 - acc: 0.9412 - val_loss: 0.8738 - val_acc: 0.8239\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "history7 = cnn2.fit(X_train, y_train, epochs=50, batch_size=batch_size, verbose=1,  \n",
    "                    validation_data=(X_val, y_val),callbacks =[earlystopping3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping4 = EarlyStopping(monitor=\"val_loss\",\n",
    "                              mode=\"min\", patience=5,\n",
    "                              restore_best_weights=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_length=200\n",
    "rnn_w2v = Sequential()\n",
    "rnn_w2v.add(Embedding(input_dim=input_dim,\n",
    "                      output_dim=output_dim,\n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=input_length,\n",
    "                      trainable=False))\n",
    "rnn_w2v.add(LSTM(128))\n",
    "rnn_w2v.add(Dropout(0.2))\n",
    "rnn_w2v.add(Dense(9,activation='softmax'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "rnn_w2v.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 200, 300)          47846400  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 48,067,209\n",
      "Trainable params: 220,809\n",
      "Non-trainable params: 47,846,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_w2v.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7175/7175 [==============================] - 2251s 314ms/step - loss: 0.9046 - acc: 0.6932 - val_loss: 0.5397 - val_acc: 0.8189\n",
      "Epoch 2/50\n",
      "7175/7175 [==============================] - 2133s 297ms/step - loss: 0.5215 - acc: 0.8248 - val_loss: 0.4964 - val_acc: 0.8298\n",
      "Epoch 3/50\n",
      "7175/7175 [==============================] - 2327s 324ms/step - loss: 0.4759 - acc: 0.8384 - val_loss: 0.4780 - val_acc: 0.8369\n",
      "Epoch 4/50\n",
      "7175/7175 [==============================] - 2350s 328ms/step - loss: 0.4448 - acc: 0.8485 - val_loss: 0.4709 - val_acc: 0.8398\n",
      "Epoch 5/50\n",
      "7175/7175 [==============================] - 2245s 313ms/step - loss: 0.4199 - acc: 0.8558 - val_loss: 0.4559 - val_acc: 0.8449\n",
      "Epoch 6/50\n",
      "7175/7175 [==============================] - 2137s 298ms/step - loss: 0.3979 - acc: 0.8638 - val_loss: 0.4521 - val_acc: 0.8468\n",
      "Epoch 7/50\n",
      "7175/7175 [==============================] - 2095s 292ms/step - loss: 0.3774 - acc: 0.8706 - val_loss: 0.4552 - val_acc: 0.8477\n",
      "Epoch 8/50\n",
      "7175/7175 [==============================] - 2600s 362ms/step - loss: 0.3588 - acc: 0.8770 - val_loss: 0.4561 - val_acc: 0.8485\n",
      "Epoch 9/50\n",
      "7175/7175 [==============================] - 2300s 321ms/step - loss: 0.3403 - acc: 0.8835 - val_loss: 0.4705 - val_acc: 0.8474\n",
      "Epoch 10/50\n",
      "7175/7175 [==============================] - 2125s 296ms/step - loss: 0.3228 - acc: 0.8902 - val_loss: 0.4755 - val_acc: 0.8481\n",
      "Epoch 11/50\n",
      "7175/7175 [==============================] - 2188s 305ms/step - loss: 0.3069 - acc: 0.8955 - val_loss: 0.4844 - val_acc: 0.8467\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "history8 = rnn_w2v.fit(X_train, y_train, epochs=50, batch_size=batch_size, verbose=1,  \n",
    "                    validation_data=(X_val, y_val),callbacks =[earlystopping4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping5 = EarlyStopping(monitor=\"val_loss\",\n",
    "                              mode=\"min\", patience=5,\n",
    "                              restore_best_weights=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_length=200\n",
    "cnn_w2v = Sequential()\n",
    "cnn_w2v.add(Embedding(input_dim=input_dim,\n",
    "                      output_dim=output_dim,\n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=input_length,\n",
    "                      trainable=False))\n",
    "cnn_w2v.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn_w2v.add(Dropout(0.2))\n",
    "#cnn.add(MaxPool1D(5))\n",
    "cnn_w2v.add(Flatten())\n",
    "cnn_w2v.add(Dense(9,activation='softmax'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "cnn_w2v.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 200, 300)          47846400  \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 196, 128)          192128    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 196, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 9)                 225801    \n",
      "=================================================================\n",
      "Total params: 48,264,329\n",
      "Trainable params: 417,929\n",
      "Non-trainable params: 47,846,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_w2v.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7175/7175 [==============================] - 941s 131ms/step - loss: 0.6715 - acc: 0.7846 - val_loss: 0.6089 - val_acc: 0.8118\n",
      "Epoch 2/50\n",
      "7175/7175 [==============================] - 929s 129ms/step - loss: 0.5635 - acc: 0.8185 - val_loss: 0.5842 - val_acc: 0.8147\n",
      "Epoch 3/50\n",
      "7175/7175 [==============================] - 886s 123ms/step - loss: 0.5100 - acc: 0.8343 - val_loss: 0.5947 - val_acc: 0.8150\n",
      "Epoch 4/50\n",
      "7175/7175 [==============================] - 862s 120ms/step - loss: 0.4655 - acc: 0.8472 - val_loss: 0.6178 - val_acc: 0.8133\n",
      "Epoch 5/50\n",
      "7175/7175 [==============================] - 847s 118ms/step - loss: 0.4272 - acc: 0.8589 - val_loss: 0.6342 - val_acc: 0.8100\n",
      "Epoch 6/50\n",
      "7175/7175 [==============================] - 853s 119ms/step - loss: 0.3957 - acc: 0.8681 - val_loss: 0.6762 - val_acc: 0.8102\n",
      "Epoch 7/50\n",
      "7175/7175 [==============================] - 859s 120ms/step - loss: 0.3702 - acc: 0.8757 - val_loss: 0.6950 - val_acc: 0.8074\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "history9 = cnn_w2v.fit(X_train, y_train, epochs=50, batch_size=batch_size, verbose=1,  \n",
    "                    validation_data=(X_val, y_val),callbacks =[earlystopping5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping7 = EarlyStopping(monitor=\"val_loss\",\n",
    "                              mode=\"min\", patience=5,\n",
    "                              restore_best_weights=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_length=200\n",
    "cnn_w2v2 = Sequential()\n",
    "cnn_w2v2.add(Embedding(input_dim=input_dim,\n",
    "                      output_dim=output_dim,\n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=input_length,\n",
    "                      trainable=False))\n",
    "cnn_w2v2.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn_w2v2.add(Dropout(0.2))\n",
    "cnn_w2v2.add(MaxPool1D(5))\n",
    "cnn_w2v2.add(Flatten())\n",
    "cnn_w2v2.add(Dense(9,activation='softmax'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "cnn_w2v2.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 300)          47846400  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 196, 128)          192128    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 196, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4992)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 44937     \n",
      "=================================================================\n",
      "Total params: 48,083,465\n",
      "Trainable params: 237,065\n",
      "Non-trainable params: 47,846,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_w2v2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7175/7175 [==============================] - 813s 113ms/step - loss: 0.6489 - acc: 0.7913 - val_loss: 0.5891 - val_acc: 0.8110\n",
      "Epoch 2/50\n",
      "7175/7175 [==============================] - 820s 114ms/step - loss: 0.5555 - acc: 0.8201 - val_loss: 0.5641 - val_acc: 0.8195\n",
      "Epoch 3/50\n",
      "7175/7175 [==============================] - 817s 114ms/step - loss: 0.5191 - acc: 0.8312 - val_loss: 0.5576 - val_acc: 0.8244\n",
      "Epoch 4/50\n",
      "7175/7175 [==============================] - 850s 118ms/step - loss: 0.4908 - acc: 0.8387 - val_loss: 0.5653 - val_acc: 0.8226\n",
      "Epoch 5/50\n",
      "7175/7175 [==============================] - 839s 117ms/step - loss: 0.4672 - acc: 0.8466 - val_loss: 0.5695 - val_acc: 0.8214\n",
      "Epoch 6/50\n",
      "7175/7175 [==============================] - 810s 113ms/step - loss: 0.4462 - acc: 0.8523 - val_loss: 0.5724 - val_acc: 0.8253\n",
      "Epoch 7/50\n",
      "7175/7175 [==============================] - 814s 113ms/step - loss: 0.4276 - acc: 0.8582 - val_loss: 0.5870 - val_acc: 0.8185\n",
      "Epoch 8/50\n",
      "7175/7175 [==============================] - 821s 114ms/step - loss: 0.4099 - acc: 0.8633 - val_loss: 0.6001 - val_acc: 0.8223\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "history11 = cnn_w2v2.fit(X_train, y_train, epochs=50, batch_size=batch_size, verbose=1,  \n",
    "                    validation_data=(X_val, y_val),callbacks =[earlystopping7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping6 = EarlyStopping(monitor=\"val_loss\",\n",
    "                              mode=\"min\", patience=5,\n",
    "                              restore_best_weights=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_length=200\n",
    "rnn_w2v2 = Sequential()\n",
    "rnn_w2v2.add(Embedding(input_dim=input_dim,\n",
    "                      output_dim=output_dim,\n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=input_length,\n",
    "                      trainable=True))\n",
    "rnn_w2v2.add(LSTM(128))\n",
    "rnn_w2v2.add(Dropout(0.2))\n",
    "rnn_w2v2.add(Dense(9,activation='softmax'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "rnn_w2v2.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 300)          47846400  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 48,067,209\n",
      "Trainable params: 48,067,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_w2v2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7175/7175 [==============================] - 6522s 909ms/step - loss: 0.7432 - acc: 0.7486 - val_loss: 0.4666 - val_acc: 0.8426\n",
      "Epoch 2/50\n",
      "7175/7175 [==============================] - 6488s 904ms/step - loss: 0.4191 - acc: 0.8591 - val_loss: 0.4366 - val_acc: 0.8524\n",
      "Epoch 3/50\n",
      "7175/7175 [==============================] - 6514s 908ms/step - loss: 0.3343 - acc: 0.8872 - val_loss: 0.4535 - val_acc: 0.8517\n",
      "Epoch 4/50\n",
      "7175/7175 [==============================] - 6494s 905ms/step - loss: 0.2658 - acc: 0.9107 - val_loss: 0.4910 - val_acc: 0.8491\n",
      "Epoch 5/50\n",
      "7175/7175 [==============================] - 6511s 908ms/step - loss: 0.2115 - acc: 0.9289 - val_loss: 0.5251 - val_acc: 0.8465\n",
      "Epoch 6/50\n",
      "7175/7175 [==============================] - 6513s 908ms/step - loss: 0.1685 - acc: 0.9439 - val_loss: 0.5836 - val_acc: 0.8452\n",
      "Epoch 7/50\n",
      "7111/7175 [============================>.] - ETA: 1:09 - loss: 0.1360 - acc: 0.9551"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[159488,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node Adam/Adam/update/AssignVariableOp (defined at <ipython-input-34-a3b4cdfafc62>:2) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_30281]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-a3b4cdfafc62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history10 = rnn_w2v2.fit(X_train, y_train, epochs=50, batch_size=batch_size, verbose=1,  \n\u001b[0m\u001b[0;32m      3\u001b[0m                     validation_data=(X_val, y_val),callbacks =[earlystopping6])\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[159488,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node Adam/Adam/update/AssignVariableOp (defined at <ipython-input-34-a3b4cdfafc62>:2) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_30281]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "history10 = rnn_w2v2.fit(X_train, y_train, epochs=50, batch_size=batch_size, verbose=1,  \n",
    "                    validation_data=(X_val, y_val),callbacks =[earlystopping6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"embedding_input:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:247 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1011 convolution_v2\n        return convolution_internal(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1141 convolution_internal\n        return op(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1881 conv1d\n        result = gen_nn_ops.conv2d(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:975 conv2d\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:3477 _create_op_internal\n        ret = Operation(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 5 from 1 for '{{node sequential/conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential/conv1d/conv1d/ExpandDims, sequential/conv1d/conv1d/ExpandDims_1)' with input shapes: [?,1,1,300], [1,5,300,128].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-ac174aff9870>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxtest9\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn_w2v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3139\u001b[0m           expand_composites=True)\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3141\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3142\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:247 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1011 convolution_v2\n        return convolution_internal(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1141 convolution_internal\n        return op(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1881 conv1d\n        result = gen_nn_ops.conv2d(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:975 conv2d\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:3477 _create_op_internal\n        ret = Operation(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 5 from 1 for '{{node sequential/conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential/conv1d/conv1d/ExpandDims, sequential/conv1d/conv1d/ExpandDims_1)' with input shapes: [?,1,1,300], [1,5,300,128].\n"
     ]
    }
   ],
   "source": [
    "xtest9 = cnn_w2v2.predict(X_test[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3,   50,    6,  508,    8,  190,  237,    5,    3, 1308,    4,\n",
       "        121, 1189,   32,   12,    7,  127, 1347, 5016,  281,    2,  629,\n",
       "       1134,    3,   14,  285,    2,  288,    3,  121,   13,    7,   22,\n",
       "         30,   36,  288,    3,   50,  742,   51,   15, 2862,    4,   42,\n",
       "        591,   10,    3,   87,   28,  601,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"embedding_input:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:247 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1011 convolution_v2\n        return convolution_internal(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1141 convolution_internal\n        return op(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1881 conv1d\n        result = gen_nn_ops.conv2d(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:975 conv2d\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:3477 _create_op_internal\n        ret = Operation(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 5 from 1 for '{{node sequential/conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential/conv1d/conv1d/ExpandDims, sequential/conv1d/conv1d/ExpandDims_1)' with input shapes: [?,1,1,300], [1,5,300,128].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-420bdc742101>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn_w2v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:247 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1011 convolution_v2\n        return convolution_internal(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1141 convolution_internal\n        return op(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1881 conv1d\n        result = gen_nn_ops.conv2d(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:975 conv2d\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:3477 _create_op_internal\n        ret = Operation(\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\virah\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 5 from 1 for '{{node sequential/conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential/conv1d/conv1d/ExpandDims, sequential/conv1d/conv1d/ExpandDims_1)' with input shapes: [?,1,1,300], [1,5,300,128].\n"
     ]
    }
   ],
   "source": [
    "np.argmax(cnn_w2v2.predict(X_test[9]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8220781936023416\n"
     ]
    }
   ],
   "source": [
    "pred_model = np.argmax(cnn_w2v2.predict(X_test), axis=-1)\n",
    "print(\"Accuracy %s\" % accuracy_score(pred_model, np.argmax(y_test, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 82.21\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy %s\" % round((accuracy_score(pred_model, np.argmax(y_test, axis=-1))*100), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "def evaluate_model(model_json, weight_h5):\n",
    "    json_file = open(model_json, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(weight_h5)\n",
    "    print(\"Model loaded\")\n",
    "\n",
    "    # evaluate loaded model on test data\n",
    "    loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    score = loaded_model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "    \n",
    "    return score[1]*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "3737/3737 [==============================] - 87s 23ms/step - loss: 0.5599 - accuracy: 0.8221\n",
      "accuracy: 82.21%\n"
     ]
    }
   ],
   "source": [
    "cnn_w2v = evaluate_model('model_4_cnn_w2v2.json', 'model_4_cnn_w2v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "3737/3737 [==============================] - 103s 28ms/step - loss: 0.5246 - accuracy: 0.8341\n",
      "accuracy: 83.41%\n"
     ]
    }
   ],
   "source": [
    "cnn = evaluate_model('model_2_cnn2.json', 'model_2_cnn2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8471252352080284\n",
      "                                                      precision    recall  f1-score   support\n",
      "\n",
      "                                     Debt collection       0.79      0.77      0.78      5172\n",
      "Credit or consumer reporting, credit repair services       0.81      0.81      0.81     12941\n",
      "         Money transfer or service, virtual currency       0.89      0.91      0.90     48487\n",
      "                                            Mortgage       0.83      0.82      0.83     24883\n",
      "                               Vehicle loan or lease       0.75      0.76      0.75      2563\n",
      "                                        Student loan       0.91      0.93      0.92     14084\n",
      "                         Credit card or prepaid card       0.63      0.44      0.52      3873\n",
      "                         Checking or savings account       0.80      0.85      0.83      5407\n",
      "                                       Personal loan       0.57      0.53      0.55      2165\n",
      "\n",
      "                                            accuracy                           0.85    119575\n",
      "                                           macro avg       0.78      0.76      0.76    119575\n",
      "                                        weighted avg       0.84      0.85      0.85    119575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_model = np.argmax(loaded_model.predict(X_test), axis=-1)\n",
    "print(\"Accuracy %s\" % accuracy_score(pred_model, np.argmax(y_test, axis=-1)))\n",
    "print(classification_report(np.argmax(y_test, axis=-1),pred_model, target_names=df['Product'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = KeyedVectors.load('vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300 # Kim uses 300 here\n",
    "num_filters = 100\n",
    "\n",
    "inputs = Input(shape=(sequence_length,), dtype='int32')\n",
    "\n",
    "# note the `trainable=False`, later we will make this layer trainable\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=sequence_length,\n",
    "                            trainable=False)(inputs)\n",
    "\n",
    "reshape = Reshape((sequence_length, embedding_dim, 1))(embedding_layer)\n",
    "\n",
    "# Note the relu activation which Kim specifically mentions\n",
    "# He also uses an l2 constraint of 3\n",
    "# Also, note that the convolution window acts on the whole 200 dimensions - that's important\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(3, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(4, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(5, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape)\n",
    "\n",
    "# perform max pooling on each of the convoluations\n",
    "maxpool_0 = MaxPool2D(pool_size=(sequence_length - 3 + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(sequence_length - 4 + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(sequence_length - 5 + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "# concat and flatten\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten = Flatten()(concatenated_tensor)\n",
    "\n",
    "# do dropout and predict\n",
    "dropout = Dropout(0.5)(flatten)\n",
    "output = Dense(units=9, activation='softmax')(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300 # Kim uses 300 here\n",
    "num_filters = 100\n",
    "\n",
    "inputs = Input(shape=(sequence_length,), dtype='int32')\n",
    "\n",
    "# note the `trainable=False`, later we will make this layer trainable\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=sequence_length,\n",
    "                            trainable=False)(inputs)\n",
    "\n",
    "reshape = Reshape((sequence_length, embedding_dim, 1))(embedding_layer)\n",
    "\n",
    "# Note the relu activation which Kim specifically mentions\n",
    "# He also uses an l2 constraint of 3\n",
    "# Also, note that the convolution window acts on the whole 200 dimensions - that's important\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(3, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(4, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(5, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape)\n",
    "\n",
    "# perform max pooling on each of the convoluations\n",
    "maxpool_0 = MaxPool2D(pool_size=(sequence_length - 3 + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(sequence_length - 4 + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(sequence_length - 5 + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "# concat and flatten\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten = Flatten()(concatenated_tensor)\n",
    "\n",
    "# do dropout and predict\n",
    "dropout = Dropout(0.5)(flatten)\n",
    "output = Dense(units=9, activation='softmax')(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 250, 300)     41523900    input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 250, 300, 1)  0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 248, 1, 100)  90100       reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 247, 1, 100)  120100      reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 246, 1, 100)  150100      reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 1, 1, 100)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 1, 1, 100)    0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 1, 1, 100)    0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 1, 100)    0           max_pooling2d_18[0][0]           \n",
      "                                                                 max_pooling2d_19[0][0]           \n",
      "                                                                 max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 300)          0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 300)          0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 9)            2709        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 41,886,909\n",
      "Trainable params: 363,009\n",
      "Non-trainable params: 41,523,900\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "319/319 [==============================] - 2811s 9s/step - loss: 1.9512 - accuracy: 0.4066 - val_loss: 1.6639 - val_accuracy: 0.4116\n",
      "Epoch 2/30\n",
      "319/319 [==============================] - 2870s 9s/step - loss: 1.6250 - accuracy: 0.4834 - val_loss: 1.5712 - val_accuracy: 0.5504\n",
      "Epoch 3/30\n",
      "319/319 [==============================] - 2851s 9s/step - loss: 1.5473 - accuracy: 0.5485 - val_loss: 1.4934 - val_accuracy: 0.5843\n",
      "Epoch 4/30\n",
      "319/319 [==============================] - 2655s 8s/step - loss: 1.4971 - accuracy: 0.5758 - val_loss: 1.4570 - val_accuracy: 0.5812\n",
      "Epoch 5/30\n",
      "319/319 [==============================] - 2652s 8s/step - loss: 1.4585 - accuracy: 0.5898 - val_loss: 1.4409 - val_accuracy: 0.5831\n",
      "Epoch 6/30\n",
      "319/319 [==============================] - 2639s 8s/step - loss: 1.4398 - accuracy: 0.5978 - val_loss: 1.3768 - val_accuracy: 0.6260\n",
      "Epoch 7/30\n",
      "319/319 [==============================] - 2633s 8s/step - loss: 1.4074 - accuracy: 0.6047 - val_loss: 1.3562 - val_accuracy: 0.6159\n",
      "Epoch 8/30\n",
      "319/319 [==============================] - 2584s 8s/step - loss: 1.3966 - accuracy: 0.6095 - val_loss: 1.3265 - val_accuracy: 0.6365\n",
      "Epoch 9/30\n",
      "319/319 [==============================] - 2619s 8s/step - loss: 1.3759 - accuracy: 0.6154 - val_loss: 1.3334 - val_accuracy: 0.6190\n",
      "Epoch 10/30\n",
      "319/319 [==============================] - 2630s 8s/step - loss: 1.3580 - accuracy: 0.6227 - val_loss: 1.2848 - val_accuracy: 0.6508\n",
      "Epoch 11/30\n",
      "319/319 [==============================] - 2641s 8s/step - loss: 1.3485 - accuracy: 0.6276 - val_loss: 1.3101 - val_accuracy: 0.6672\n",
      "Epoch 12/30\n",
      "319/319 [==============================] - 2627s 8s/step - loss: 1.3334 - accuracy: 0.6337 - val_loss: 1.2741 - val_accuracy: 0.6543\n",
      "Epoch 13/30\n",
      "319/319 [==============================] - 2599s 8s/step - loss: 1.3265 - accuracy: 0.6376 - val_loss: 1.2876 - val_accuracy: 0.6691\n",
      "Epoch 14/30\n",
      "319/319 [==============================] - 2491s 8s/step - loss: 1.3176 - accuracy: 0.6425 - val_loss: 1.2754 - val_accuracy: 0.6643\n",
      "Epoch 15/30\n",
      "319/319 [==============================] - 2463s 8s/step - loss: 1.3036 - accuracy: 0.6470 - val_loss: 1.2420 - val_accuracy: 0.6550\n",
      "Epoch 16/30\n",
      "319/319 [==============================] - 2566s 8s/step - loss: 1.2929 - accuracy: 0.6498 - val_loss: 1.2308 - val_accuracy: 0.6598\n",
      "Epoch 17/30\n",
      "319/319 [==============================] - 2645s 8s/step - loss: 1.2909 - accuracy: 0.6515 - val_loss: 1.2289 - val_accuracy: 0.6666\n",
      "Epoch 18/30\n",
      "319/319 [==============================] - 2640s 8s/step - loss: 1.2921 - accuracy: 0.6533 - val_loss: 1.2297 - val_accuracy: 0.6857\n",
      "Epoch 19/30\n",
      "319/319 [==============================] - 2650s 8s/step - loss: 1.2729 - accuracy: 0.6577 - val_loss: 1.1922 - val_accuracy: 0.6999\n",
      "Epoch 20/30\n",
      "319/319 [==============================] - 2644s 8s/step - loss: 1.2735 - accuracy: 0.6582 - val_loss: 1.1796 - val_accuracy: 0.6930\n",
      "Epoch 21/30\n",
      "319/319 [==============================] - 2623s 8s/step - loss: 1.2620 - accuracy: 0.6609 - val_loss: 1.2170 - val_accuracy: 0.7037\n",
      "Epoch 22/30\n",
      "319/319 [==============================] - 2619s 8s/step - loss: 1.2694 - accuracy: 0.6603 - val_loss: 1.1717 - val_accuracy: 0.7015\n",
      "Epoch 23/30\n",
      "319/319 [==============================] - 2674s 8s/step - loss: 1.2546 - accuracy: 0.6626 - val_loss: 1.1824 - val_accuracy: 0.6979\n",
      "Epoch 24/30\n",
      "319/319 [==============================] - 2697s 8s/step - loss: 1.2520 - accuracy: 0.6634 - val_loss: 1.1736 - val_accuracy: 0.6955\n",
      "Epoch 25/30\n",
      "319/319 [==============================] - 2655s 8s/step - loss: 1.2475 - accuracy: 0.6642 - val_loss: 1.1830 - val_accuracy: 0.6993\n",
      "Epoch 26/30\n",
      "319/319 [==============================] - 2803s 9s/step - loss: 1.2442 - accuracy: 0.6640 - val_loss: 1.1892 - val_accuracy: 0.6981\n",
      "Epoch 27/30\n",
      "319/319 [==============================] - 2905s 9s/step - loss: 1.2388 - accuracy: 0.6670 - val_loss: 1.1414 - val_accuracy: 0.6966\n",
      "Epoch 28/30\n",
      "319/319 [==============================] - 2957s 9s/step - loss: 1.2347 - accuracy: 0.6673 - val_loss: 1.1635 - val_accuracy: 0.6919\n",
      "Epoch 29/30\n",
      "319/319 [==============================] - 2852s 9s/step - loss: 1.2360 - accuracy: 0.6695 - val_loss: 1.1988 - val_accuracy: 0.7076\n",
      "Epoch 30/30\n",
      "319/319 [==============================] - 2876s 9s/step - loss: 1.2356 - accuracy: 0.6687 - val_loss: 1.1806 - val_accuracy: 0.7037\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1500 # Kim uses 50 here, I have a slightly smaller sample size than num\n",
    "history = model.fit(x_tr_seq, y_train, epochs=30, batch_size=batch_size, verbose=1,  \n",
    "                    validation_data=(x_val_seq, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hist(hist, json_name, csv_name):\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(hist.history) \n",
    "\n",
    "    # save to json:  \n",
    "    hist_json_file = json_name  \n",
    "    with open(hist_json_file, mode='w') as f:\n",
    "        hist_df.to_json(f)\n",
    "\n",
    "    # or save to csv: \n",
    "    hist_csv_file = csv_name \n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hist(history9, 'history9.json', 'history9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "import json\n",
    "history_dict = json.load(open('history9.json', 'r'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': {'0': 0.6714661121,\n",
       "  '1': 0.5635042191,\n",
       "  '2': 0.5100016594,\n",
       "  '3': 0.4654912651,\n",
       "  '4': 0.4271643758,\n",
       "  '5': 0.3957315683,\n",
       "  '6': 0.3702034354},\n",
       " 'acc': {'0': 0.7846115828,\n",
       "  '1': 0.8185178638,\n",
       "  '2': 0.8342625499,\n",
       "  '3': 0.8472446799,\n",
       "  '4': 0.858869195,\n",
       "  '5': 0.8681074977,\n",
       "  '6': 0.8757261634},\n",
       " 'val_loss': {'0': 0.6088611484,\n",
       "  '1': 0.584184885,\n",
       "  '2': 0.5947144628,\n",
       "  '3': 0.6178187728,\n",
       "  '4': 0.6341908574,\n",
       "  '5': 0.6762247682,\n",
       "  '6': 0.6949911118},\n",
       " 'val_acc': {'0': 0.8117583394,\n",
       "  '1': 0.8147187829,\n",
       "  '2': 0.8149780631,\n",
       "  '3': 0.8132552505,\n",
       "  '4': 0.8100020885,\n",
       "  '5': 0.8101526499,\n",
       "  '6': 0.8073677421}}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.671466</td>\n",
       "      <td>0.784612</td>\n",
       "      <td>0.608861</td>\n",
       "      <td>0.811758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.563504</td>\n",
       "      <td>0.818518</td>\n",
       "      <td>0.584185</td>\n",
       "      <td>0.814719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.510002</td>\n",
       "      <td>0.834263</td>\n",
       "      <td>0.594714</td>\n",
       "      <td>0.814978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.465491</td>\n",
       "      <td>0.847245</td>\n",
       "      <td>0.617819</td>\n",
       "      <td>0.813255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.427164</td>\n",
       "      <td>0.858869</td>\n",
       "      <td>0.634191</td>\n",
       "      <td>0.810002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.395732</td>\n",
       "      <td>0.868107</td>\n",
       "      <td>0.676225</td>\n",
       "      <td>0.810153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.370203</td>\n",
       "      <td>0.875726</td>\n",
       "      <td>0.694991</td>\n",
       "      <td>0.807368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      loss       acc  val_loss   val_acc\n",
       "0           0  0.671466  0.784612  0.608861  0.811758\n",
       "1           1  0.563504  0.818518  0.584185  0.814719\n",
       "2           2  0.510002  0.834263  0.594714  0.814978\n",
       "3           3  0.465491  0.847245  0.617819  0.813255\n",
       "4           4  0.427164  0.858869  0.634191  0.810002\n",
       "5           5  0.395732  0.868107  0.676225  0.810153\n",
       "6           6  0.370203  0.875726  0.694991  0.807368"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainHistoryDict_model_4_cnn_w2v', 'wb') as file_pi:\n",
    "        pickle.dump(history9.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pickle.load(open('trainHistoryDict_model_3_rnn_w2v', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6714661121368408,\n",
       "  0.5635042190551758,\n",
       "  0.5100016593933105,\n",
       "  0.46549126505851746,\n",
       "  0.42716437578201294,\n",
       "  0.3957315683364868,\n",
       "  0.37020343542099],\n",
       " 'acc': [0.7846115827560425,\n",
       "  0.8185178637504578,\n",
       "  0.8342625498771667,\n",
       "  0.8472446799278259,\n",
       "  0.858869194984436,\n",
       "  0.8681074976921082,\n",
       "  0.8757261633872986],\n",
       " 'val_loss': [0.6088611483573914,\n",
       "  0.5841848850250244,\n",
       "  0.5947144627571106,\n",
       "  0.6178187727928162,\n",
       "  0.6341908574104309,\n",
       "  0.6762247681617737,\n",
       "  0.6949911117553711],\n",
       " 'val_acc': [0.8117583394050598,\n",
       "  0.8147187829017639,\n",
       "  0.8149780631065369,\n",
       "  0.813255250453949,\n",
       "  0.8100020885467529,\n",
       "  0.8101526498794556,\n",
       "  0.807367742061615]}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(history, model, history_file, model_json, model_weight):\n",
    "    with open(history_file, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "    # serialize model to JSON\n",
    "    model_to_json = model.to_json()\n",
    "    with open(model_json, \"w\") as json_file:\n",
    "        json_file.write(model_to_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(model_weight)\n",
    "    print(\"model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "save_model(history11, cnn_w2v2,'trainHistoryDict_model_4_cnn_w2v2',\n",
    "          'model_4_cnn_w2v2.json', 'model_4_cnn_w2v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_4_cnn_w2v = cnn_w2v.to_json()\n",
    "with open(\"model_4_cnn_w2v.json\", \"w\") as json_file:\n",
    "    json_file.write(model_4_cnn_w2v)\n",
    "# serialize weights to HDF5\n",
    "cnn_w2v.save_weights(\"model_4_cnn_w2v.h5\")\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "3737/3737 [==============================] - 276s 74ms/step - loss: 0.4516 - accuracy: 0.8471\n",
      "accuracy: 84.71%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model_3_rnn_w2v.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_3_rnn_w2v.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x14e3981a3a0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.300d.txt',  encoding=\"utf8\")\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((size_of_vocabulary, 300))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = model['word']\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138414, 300)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 250, 300)          41524200  \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                19264     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 41,544,049\n",
      "Trainable params: 19,849\n",
      "Non-trainable params: 41,524,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(size_of_vocabulary, 300, \n",
    "                           weights=[embedding_matrix], \n",
    "                           input_length=250, \n",
    "                           trainable=False))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "467/467 [==============================] - 91s 196ms/step - loss: 1.3450 - acc: 0.5519 - val_loss: 1.0538 - val_acc: 0.6597\n",
      "Epoch 2/25\n",
      "467/467 [==============================] - 84s 180ms/step - loss: 0.9789 - acc: 0.6767 - val_loss: 0.9331 - val_acc: 0.6936\n",
      "Epoch 3/25\n",
      "467/467 [==============================] - 84s 180ms/step - loss: 0.9064 - acc: 0.6971 - val_loss: 0.8885 - val_acc: 0.7043\n",
      "Epoch 4/25\n",
      "467/467 [==============================] - 85s 183ms/step - loss: 0.8764 - acc: 0.7061 - val_loss: 0.8615 - val_acc: 0.7110\n",
      "Epoch 5/25\n",
      "467/467 [==============================] - 86s 185ms/step - loss: 0.8577 - acc: 0.7115 - val_loss: 0.8516 - val_acc: 0.7135\n",
      "Epoch 6/25\n",
      "467/467 [==============================] - 85s 182ms/step - loss: 0.8452 - acc: 0.7151 - val_loss: 0.8400 - val_acc: 0.7167\n",
      "Epoch 7/25\n",
      "467/467 [==============================] - 88s 189ms/step - loss: 0.8370 - acc: 0.7175 - val_loss: 0.8369 - val_acc: 0.7153\n",
      "Epoch 8/25\n",
      "467/467 [==============================] - 85s 181ms/step - loss: 0.8299 - acc: 0.7195 - val_loss: 0.8273 - val_acc: 0.7205\n",
      "Epoch 9/25\n",
      "467/467 [==============================] - 82s 176ms/step - loss: 0.8261 - acc: 0.7211 - val_loss: 0.8264 - val_acc: 0.7206\n",
      "Epoch 10/25\n",
      "467/467 [==============================] - 83s 177ms/step - loss: 0.8211 - acc: 0.7224 - val_loss: 0.8216 - val_acc: 0.7232\n",
      "Epoch 11/25\n",
      "467/467 [==============================] - 82s 175ms/step - loss: 0.8184 - acc: 0.7232 - val_loss: 0.8192 - val_acc: 0.7232\n",
      "Epoch 12/25\n",
      "467/467 [==============================] - 83s 179ms/step - loss: 0.8159 - acc: 0.7240 - val_loss: 0.8138 - val_acc: 0.7261\n",
      "Epoch 13/25\n",
      "467/467 [==============================] - 85s 182ms/step - loss: 0.8142 - acc: 0.7245 - val_loss: 0.8114 - val_acc: 0.7268\n",
      "Epoch 14/25\n",
      "467/467 [==============================] - 88s 188ms/step - loss: 0.8113 - acc: 0.7253 - val_loss: 0.8116 - val_acc: 0.7261\n",
      "Epoch 15/25\n",
      "467/467 [==============================] - 83s 179ms/step - loss: 0.8102 - acc: 0.7258 - val_loss: 0.8093 - val_acc: 0.7268\n",
      "Epoch 16/25\n",
      "467/467 [==============================] - 84s 179ms/step - loss: 0.8086 - acc: 0.7266 - val_loss: 0.8118 - val_acc: 0.7250\n",
      "Epoch 17/25\n",
      "467/467 [==============================] - 89s 190ms/step - loss: 0.8063 - acc: 0.7273 - val_loss: 0.8039 - val_acc: 0.7292\n",
      "Epoch 18/25\n",
      "467/467 [==============================] - 82s 175ms/step - loss: 0.8058 - acc: 0.7274 - val_loss: 0.8067 - val_acc: 0.7283\n",
      "Epoch 19/25\n",
      "467/467 [==============================] - 84s 181ms/step - loss: 0.8041 - acc: 0.7275 - val_loss: 0.8029 - val_acc: 0.7281\n",
      "Epoch 20/25\n",
      "467/467 [==============================] - 83s 178ms/step - loss: 0.8027 - acc: 0.7279 - val_loss: 0.8043 - val_acc: 0.7269\n",
      "Epoch 21/25\n",
      "467/467 [==============================] - 86s 185ms/step - loss: 0.8015 - acc: 0.7282 - val_loss: 0.8009 - val_acc: 0.7282\n",
      "Epoch 22/25\n",
      "467/467 [==============================] - 83s 177ms/step - loss: 0.8002 - acc: 0.7287 - val_loss: 0.8020 - val_acc: 0.7279\n",
      "Epoch 23/25\n",
      "467/467 [==============================] - 83s 178ms/step - loss: 0.7987 - acc: 0.7292 - val_loss: 0.8019 - val_acc: 0.7287\n",
      "Epoch 24/25\n",
      "467/467 [==============================] - 82s 175ms/step - loss: 0.7974 - acc: 0.7295 - val_loss: 0.8027 - val_acc: 0.7268\n",
      "Epoch 25/25\n",
      "467/467 [==============================] - 81s 173ms/step - loss: 0.7967 - acc: 0.7297 - val_loss: 0.8045 - val_acc: 0.7288\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_tr_seq, y_train, epochs=25, validation_data=(x_val_seq, y_val), batch_size=1025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 250, 300)          41524200  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 250, 128)          219648    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 41,752,689\n",
      "Trainable params: 228,489\n",
      "Non-trainable params: 41,524,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model.add(Embedding(size_of_vocabulary,300,weights=[embedding_matrix],input_length=250,trainable=False)) \n",
    "\n",
    "#lstm layer\n",
    "model.add(LSTM(128,return_sequences=True,dropout=0.2))\n",
    "\n",
    "#Global Maxpooling\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model.add(Dense(64,activation='relu')) \n",
    "model.add(Dense(9,activation='softmax')) \n",
    "\n",
    "#Add loss function, metrics, optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc']) \n",
    "\n",
    "#Adding callbacks\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "#Print summary of model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "467/467 [==============================] - 4323s 9s/step - loss: 0.8615 - acc: 0.7115 - val_loss: 0.6122 - val_acc: 0.7921\n",
      "Epoch 2/10\n",
      "467/467 [==============================] - 4308s 9s/step - loss: 0.5873 - acc: 0.7995 - val_loss: 0.5511 - val_acc: 0.8123\n",
      "Epoch 3/10\n",
      "467/467 [==============================] - 6148s 13s/step - loss: 0.5415 - acc: 0.8153 - val_loss: 0.5170 - val_acc: 0.8240\n",
      "Epoch 4/10\n",
      "467/467 [==============================] - 5154s 11s/step - loss: 0.5177 - acc: 0.8230 - val_loss: 0.4987 - val_acc: 0.8291\n",
      "Epoch 5/10\n",
      "467/467 [==============================] - 3986s 9s/step - loss: 0.4996 - acc: 0.8287 - val_loss: 0.4851 - val_acc: 0.8326\n",
      "Epoch 6/10\n",
      "467/467 [==============================] - 4827s 10s/step - loss: 0.4855 - acc: 0.8330 - val_loss: 0.4773 - val_acc: 0.8358\n",
      "Epoch 7/10\n",
      "467/467 [==============================] - 5377s 12s/step - loss: 0.4739 - acc: 0.8370 - val_loss: 0.4712 - val_acc: 0.8375\n",
      "Epoch 8/10\n",
      "467/467 [==============================] - 4478s 10s/step - loss: 0.4635 - acc: 0.8404 - val_loss: 0.4754 - val_acc: 0.8366\n",
      "Epoch 9/10\n",
      "467/467 [==============================] - 3828s 8s/step - loss: 0.4554 - acc: 0.8432 - val_loss: 0.4599 - val_acc: 0.8415\n",
      "Epoch 10/10\n",
      "467/467 [==============================] - 3821s 8s/step - loss: 0.4481 - acc: 0.8459 - val_loss: 0.4647 - val_acc: 0.8397\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr_seq),np.array(y_train),batch_size=1025,epochs=10,\n",
    "                    validation_data=(np.array(x_val_seq),np.array(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy %s\" % accuracy_score(pred_model, np.argmax(y_val, axis=-1)))\n",
    "print(classification_report(np.argmax(y_val, axis=-1),pred_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8396571189629939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78      5172\n",
      "           1       0.80      0.81      0.81     12941\n",
      "           2       0.86      0.92      0.89     48487\n",
      "           3       0.86      0.77      0.81     24883\n",
      "           4       0.81      0.69      0.74      2563\n",
      "           5       0.90      0.92      0.91     14084\n",
      "           6       0.60      0.47      0.53      3873\n",
      "           7       0.82      0.82      0.82      5407\n",
      "           8       0.58      0.50      0.54      2165\n",
      "\n",
      "    accuracy                           0.84    119575\n",
      "   macro avg       0.78      0.75      0.76    119575\n",
      "weighted avg       0.84      0.84      0.84    119575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_model = np.argmax(model.predict(x_val_seq), axis=-1)\n",
    "print(\"Accuracy %s\" % accuracy_score(pred_model, np.argmax(y_val, axis=-1)))\n",
    "print(classification_report(np.argmax(y_val, axis=-1),pred_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset(X_data) and the label (y_data) \n",
    "X_data = df['new']\n",
    "y_data = df['Product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_data.values\n",
    "y = y_data.values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=666, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_val   = lb.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(lowercase=False, min_df=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(X_train)\n",
    "X_val  = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               20261248  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 99        \n",
      "=================================================================\n",
      "Total params: 20,270,253\n",
      "Trainable params: 20,270,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu', kernel_regularizer=regularizers.l2(0.01), kernel_initializer='glorot_normal'))\n",
    "model.add(Dense(9, activation='softmax', kernel_regularizer=regularizers.l2(0.01), kernel_initializer='glorot_uniform'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                8843264   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 99        \n",
      "=================================================================\n",
      "Total params: 8,844,013\n",
      "Trainable params: 8,844,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "467/467 [==============================] - 29s 61ms/step - loss: 0.7395 - acc: 0.7966 - val_loss: 0.5425 - val_acc: 0.8374\n",
      "Epoch 2/5\n",
      "467/467 [==============================] - 28s 61ms/step - loss: 0.4547 - acc: 0.8566 - val_loss: 0.4918 - val_acc: 0.8453\n",
      "Epoch 3/5\n",
      "467/467 [==============================] - 30s 65ms/step - loss: 0.3707 - acc: 0.8787 - val_loss: 0.4752 - val_acc: 0.8501\n",
      "Epoch 4/5\n",
      "467/467 [==============================] - 33s 70ms/step - loss: 0.3153 - acc: 0.8958 - val_loss: 0.4856 - val_acc: 0.8507\n",
      "Epoch 5/5\n",
      "467/467 [==============================] - 32s 69ms/step - loss: 0.2723 - acc: 0.9098 - val_loss: 0.4937 - val_acc: 0.8518\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_val, y_val), batch_size=1025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8517666736357934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      5172\n",
      "           1       0.82      0.80      0.81     12941\n",
      "           2       0.89      0.91      0.90     48487\n",
      "           3       0.82      0.84      0.83     24883\n",
      "           4       0.79      0.73      0.76      2563\n",
      "           5       0.91      0.93      0.92     14084\n",
      "           6       0.58      0.48      0.52      3873\n",
      "           7       0.87      0.87      0.87      5407\n",
      "           8       0.60      0.37      0.46      2165\n",
      "\n",
      "    accuracy                           0.85    119575\n",
      "   macro avg       0.78      0.75      0.76    119575\n",
      "weighted avg       0.85      0.85      0.85    119575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_model = np.argmax(model.predict(X_val), axis=-1)\n",
    "print(\"Accuracy %s\" % accuracy_score(pred_model, np.argmax(y_val, axis=-1)))\n",
    "print(classification_report(np.argmax(y_val, axis=-1),pred_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    " from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 179260 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['narrative'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pad_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-6ca0645d986c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'narrative'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Shape of data tensor:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pad_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['narrative'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(df['Product']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model2.add(SpatialDropout1D(0.2))\n",
    "model2.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model2.add(Dense(13, activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<119575x85471 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6529261 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1068112e-04, 6.5074964e-05, 1.1395631e-01, ..., 3.2094610e-03,\n",
       "        2.7522133e-04, 9.6498424e-04],\n",
       "       [3.6948888e-05, 9.3445033e-06, 1.9738725e-03, ..., 1.3473543e-03,\n",
       "        6.9955429e-05, 6.3340244e-04],\n",
       "       [9.5675557e-07, 5.4205211e-05, 9.9896431e-01, ..., 9.0579044e-07,\n",
       "        7.1399825e-07, 5.1870991e-08],\n",
       "       ...,\n",
       "       [1.4687306e-05, 6.4322440e-04, 6.2166578e-03, ..., 1.3471496e-03,\n",
       "        1.4947487e-04, 9.1205431e-05],\n",
       "       [1.0232003e-08, 7.6825409e-06, 9.9998629e-01, ..., 9.0880432e-09,\n",
       "        7.1876329e-08, 3.2951439e-10],\n",
       "       [1.9863099e-04, 3.4326483e-03, 1.7260011e-01, ..., 2.5184050e-03,\n",
       "        7.0130843e-04, 3.0174191e-04]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>narrative</th>\n",
       "      <th>Product</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transworld systems inc. \\nis trying to collect...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Over the past 2 weeks, I have been receiving e...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pioneer has committed several federal violatio...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Previously, on XX/XX/XXXX, XX/XX/XXXX, and XX/...</td>\n",
       "      <td>Credit or consumer reporting, credit repair se...</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hello This complaint is against the three cred...</td>\n",
       "      <td>Credit or consumer reporting, credit repair se...</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823677</th>\n",
       "      <td>I made a purchase of {$500.00} on XXXX XXXX, 2...</td>\n",
       "      <td>Credit card or prepaid card</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823679</th>\n",
       "      <td>I have been a victim if inquiry issue,</td>\n",
       "      <td>Credit or consumer reporting, credit repair se...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823680</th>\n",
       "      <td>On XXXX XXXX, 2015, I contacted XXXX XXXX, who...</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823681</th>\n",
       "      <td>I can not get from chase who services my mortg...</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823682</th>\n",
       "      <td>cfbp i would Like to file a complaint on Exper...</td>\n",
       "      <td>Credit or consumer reporting, credit repair se...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605163 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 narrative  \\\n",
       "1        transworld systems inc. \\nis trying to collect...   \n",
       "3        Over the past 2 weeks, I have been receiving e...   \n",
       "6        Pioneer has committed several federal violatio...   \n",
       "8        Previously, on XX/XX/XXXX, XX/XX/XXXX, and XX/...   \n",
       "9        Hello This complaint is against the three cred...   \n",
       "...                                                    ...   \n",
       "1823677  I made a purchase of {$500.00} on XXXX XXXX, 2...   \n",
       "1823679             I have been a victim if inquiry issue,   \n",
       "1823680  On XXXX XXXX, 2015, I contacted XXXX XXXX, who...   \n",
       "1823681  I can not get from chase who services my mortg...   \n",
       "1823682  cfbp i would Like to file a complaint on Exper...   \n",
       "\n",
       "                                                   Product  word_count  \n",
       "1                                          Debt collection          18  \n",
       "3                                          Debt collection          78  \n",
       "6                                          Debt collection         152  \n",
       "8        Credit or consumer reporting, credit repair se...         171  \n",
       "9        Credit or consumer reporting, credit repair se...         428  \n",
       "...                                                    ...         ...  \n",
       "1823677                        Credit card or prepaid card          44  \n",
       "1823679  Credit or consumer reporting, credit repair se...           8  \n",
       "1823680                                           Mortgage         331  \n",
       "1823681                                           Mortgage          21  \n",
       "1823682  Credit or consumer reporting, credit repair se...         150  \n",
       "\n",
       "[605163 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    #plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history['acc']\n",
    "    val_acc = history['val_acc']\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    #plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_vect = df[['narrative']]\n",
    "columnTransformer = ColumnTransformer( [('tfidf',TfidfVectorizer(stop_words=None, max_features=100000),'narrative')],\n",
    "remainder='drop')\n",
    "vector_transformer = columnTransformer.fit(before_vect)\n",
    "vectorized_df = vector_transformer.transform(before_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<592935x99272 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 32223236 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetTransformer = ColumnTransformer( [('E',OneHotEncoder(dtype='int'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Product'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Debt collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Debt collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823678</th>\n",
       "      <td>Bank account or service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823679</th>\n",
       "      <td>Credit reporting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823680</th>\n",
       "      <td>Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823681</th>\n",
       "      <td>Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823682</th>\n",
       "      <td>Credit reporting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1823683 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Product\n",
       "0        Credit reporting, credit repair services, or o...\n",
       "1                                          Debt collection\n",
       "2        Credit reporting, credit repair services, or o...\n",
       "3                                          Debt collection\n",
       "4        Credit reporting, credit repair services, or o...\n",
       "...                                                    ...\n",
       "1823678                            Bank account or service\n",
       "1823679                                   Credit reporting\n",
       "1823680                                           Mortgage\n",
       "1823681                                           Mortgage\n",
       "1823682                                   Credit reporting\n",
       "\n",
       "[1823683 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7989275484092732\n",
      "                                                      precision    recall  f1-score   support\n",
      "\n",
      "                         Checking or savings account       0.78      0.82      0.80     72885\n",
      "                         Credit card or prepaid card       0.78      0.82      0.80     73008\n",
      "Credit or consumer reporting, credit repair services       0.76      0.76      0.76     72446\n",
      "                                     Debt collection       0.75      0.79      0.77     72432\n",
      "         Money transfer or service, virtual currency       0.85      0.84      0.84     73035\n",
      "                                            Mortgage       0.89      0.95      0.92     72579\n",
      "                                       Personal loan       0.81      0.42      0.56     72688\n",
      "                                        Student loan       0.91      0.93      0.92     72801\n",
      "                               Vehicle loan or lease       0.69      0.85      0.76     72701\n",
      "\n",
      "                                            accuracy                           0.80    654575\n",
      "                                           macro avg       0.80      0.80      0.79    654575\n",
      "                                        weighted avg       0.80      0.80      0.79    654575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=777)\n",
    "X_ROS, y_ROS = ros.fit_sample(vectorized_df, y)\n",
    "X_train, x_test, Y_train, y_test = train_test_split(X_ROS,y_ROS,test_size=0.3,random_state=42)\n",
    "sgd = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "sgd.fit(X_train, Y_train)\n",
    "pred_sgd = sgd.predict(x_test)\n",
    "print(\"Accuracy %s\" % accuracy_score(pred_sgd,y_test))\n",
    "print(classification_report(y_test,pred_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\virah\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8304777909330482\n",
      "                                                      precision    recall  f1-score   support\n",
      "\n",
      "                         Checking or savings account       0.83      0.86      0.84     72885\n",
      "                         Credit card or prepaid card       0.82      0.86      0.84     73008\n",
      "Credit or consumer reporting, credit repair services       0.78      0.76      0.77     72446\n",
      "                                     Debt collection       0.79      0.82      0.80     72432\n",
      "         Money transfer or service, virtual currency       0.88      0.88      0.88     73035\n",
      "                                            Mortgage       0.92      0.96      0.94     72579\n",
      "                                       Personal loan       0.84      0.50      0.62     72688\n",
      "                                        Student loan       0.94      0.95      0.94     72801\n",
      "                               Vehicle loan or lease       0.71      0.89      0.79     72701\n",
      "\n",
      "                                            accuracy                           0.83    654575\n",
      "                                           macro avg       0.83      0.83      0.83    654575\n",
      "                                        weighted avg       0.83      0.83      0.83    654575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=777,k_neighbors=18)\n",
    "X_smote,y_smote = smote.fit_sample(vectorized_df,y)\n",
    "X_train, x_test, Y_train, y_test = train_test_split(X_smote,y_smote,test_size=0.3,random_state=42)\n",
    "sgd = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "sgd.fit(X_train, Y_train)\n",
    "pred_sgd = sgd.predict(x_test)\n",
    "print(\"Accuracy %s\" % accuracy_score(pred_sgd,y_test))\n",
    "print(classification_report(y_test,pred_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
