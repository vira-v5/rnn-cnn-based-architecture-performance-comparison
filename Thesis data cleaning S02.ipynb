{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = pd.read_csv(\"complaints.csv\")\n",
    "df = complaints[['Consumer complaint narrative','Product']]\n",
    "df = df.rename(columns={'Consumer complaint narrative': \"narrative\"})\n",
    "df = df[df.narrative.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['narrative'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df[df['word_count'] >= 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['Product'] == 'Credit reporting') | \n",
    "       (df['Product']=='Credit reporting, credit repair services, or other personal consumer reports'), \n",
    "       'Product'] = 'Credit or consumer reporting, credit repair services'\n",
    "\n",
    "df.loc[(df['Product'] == 'Credit card') | \n",
    "       (df['Product']=='Credit card or prepaid card') |\n",
    "       (df['Product'] == 'Prepaid card'), \n",
    "       'Product'] = 'Credit card or prepaid card'\n",
    "\n",
    "df.loc[(df['Product'] == 'Money transfer, virtual currency, or money service') | \n",
    "       (df['Product']=='Money transfers') |\n",
    "       (df['Product'] == 'Virtual currency'), \n",
    "       'Product'] = 'Money transfer or service, virtual currency'\n",
    "\n",
    "df.loc[(df['Product'] == 'Payday loan') | \n",
    "       (df['Product']=='Payday loan, title loan, or personal loan') |\n",
    "       (df['Product'] == 'Consumer Loan'), \n",
    "       'Product'] = 'Personal loan'\n",
    "\n",
    "df.loc[(df['Product'] == 'Bank account or service') | \n",
    "       (df['Product']=='Other financial service'), \n",
    "       'Product'] = 'Other financial service'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df[df['Product'] != 'Other financial service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>narrative</th>\n",
       "      <th>Product</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transworld systems inc. \\nis trying to collect...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Over the past 2 weeks, I have been receiving e...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pioneer has committed several federal violatio...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Previously, on XX/XX/XXXX, XX/XX/XXXX, and XX/...</td>\n",
       "      <td>Credit or consumer reporting, credit repair se...</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hello This complaint is against the three cred...</td>\n",
       "      <td>Credit or consumer reporting, credit repair se...</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823676</th>\n",
       "      <td>1 : Mailing Address is incorrect. \\n2 : Date o...</td>\n",
       "      <td>Personal loan</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823677</th>\n",
       "      <td>I made a purchase of {$500.00} on XXXX XXXX, 2...</td>\n",
       "      <td>Credit card or prepaid card</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823680</th>\n",
       "      <td>On XXXX XXXX, 2015, I contacted XXXX XXXX, who...</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823681</th>\n",
       "      <td>I can not get from chase who services my mortg...</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823682</th>\n",
       "      <td>cfbp i would Like to file a complaint on Exper...</td>\n",
       "      <td>Credit or consumer reporting, credit repair se...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597874 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 narrative  \\\n",
       "1        transworld systems inc. \\nis trying to collect...   \n",
       "3        Over the past 2 weeks, I have been receiving e...   \n",
       "6        Pioneer has committed several federal violatio...   \n",
       "8        Previously, on XX/XX/XXXX, XX/XX/XXXX, and XX/...   \n",
       "9        Hello This complaint is against the three cred...   \n",
       "...                                                    ...   \n",
       "1823676  1 : Mailing Address is incorrect. \\n2 : Date o...   \n",
       "1823677  I made a purchase of {$500.00} on XXXX XXXX, 2...   \n",
       "1823680  On XXXX XXXX, 2015, I contacted XXXX XXXX, who...   \n",
       "1823681  I can not get from chase who services my mortg...   \n",
       "1823682  cfbp i would Like to file a complaint on Exper...   \n",
       "\n",
       "                                                   Product  word_count  \n",
       "1                                          Debt collection          18  \n",
       "3                                          Debt collection          78  \n",
       "6                                          Debt collection         152  \n",
       "8        Credit or consumer reporting, credit repair se...         171  \n",
       "9        Credit or consumer reporting, credit repair se...         428  \n",
       "...                                                    ...         ...  \n",
       "1823676                                      Personal loan          19  \n",
       "1823677                        Credit card or prepaid card          44  \n",
       "1823680                                           Mortgage         331  \n",
       "1823681                                           Mortgage          21  \n",
       "1823682  Credit or consumer reporting, credit repair se...         150  \n",
       "\n",
       "[597874 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          transworld systems inc. \\nis trying to collect...\n",
       "3          Over the past 2 weeks, I have been receiving e...\n",
       "6          Pioneer has committed several federal violatio...\n",
       "8          Previously, on XX/XX/XXXX, XX/XX/XXXX, and XX/...\n",
       "9          Hello This complaint is against the three cred...\n",
       "                                 ...                        \n",
       "1823676    1 : Mailing Address is incorrect. \\n2 : Date o...\n",
       "1823677    I made a purchase of {$500.00} on XXXX XXXX, 2...\n",
       "1823680    On XXXX XXXX, 2015, I contacted XXXX XXXX, who...\n",
       "1823681    I can not get from chase who services my mortg...\n",
       "1823682    cfbp i would Like to file a complaint on Exper...\n",
       "Name: narrative, Length: 597874, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['narrative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning inspired by:\n",
    "https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\virah\\anaconda3\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences, verbose=True):\n",
    "    \"\"\"\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in tqdm(sentences, disable= (not verbose)):\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 597874/597874 [03:41<00:00, 2702.35it/s] \n",
      "100%|██████████| 597874/597874 [02:23<00:00, 4165.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'transworld': 65, 'systems': 3213, 'inc.': 290, 'is': 1054633, 'trying': 67193}\n"
     ]
    }
   ],
   "source": [
    "sentences = df['narrative'].progress_apply(lambda x: str(x).split()).values\n",
    "vocab = build_vocab(sentences)\n",
    "print({k: vocab[k] for k in list(vocab)[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_path = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "embeddings_index = KeyedVectors.load_word2vec_format(news_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x1b38c74f3a0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.35 GiB for an array with shape (900000000,) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-0f1ca1b8ae0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0membedding_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vectors.kv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1553\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWordEmbeddingsKeyedVectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFastTextKeyedVectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'compatible_hash'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseKeyedVectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loaded %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36m_load_specials\u001b[1;34m(self, fname, mmap, compress, subname)\u001b[0m\n\u001b[0;32m    476\u001b[0m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mignore_deprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    450\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_memmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[0;32m    453\u001b[0m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0;32m    454\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m             \u001b[1;31m# We can use the fast fromfile() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# This is not a real file. We have to read it the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.35 GiB for an array with shape (900000000,) and data type float32"
     ]
    }
   ],
   "source": [
    "embedding_index = KeyedVectors.load('vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator \n",
    "\n",
    "def check_coverage(vocab,embeddings_index):\n",
    "    a = {}\n",
    "    oov = {}\n",
    "    k = 0\n",
    "    i = 0\n",
    "    for word in tqdm(vocab):\n",
    "        try:\n",
    "            a[word] = embeddings_index[word]\n",
    "            k += vocab[word]\n",
    "        except:\n",
    "            oov[word] = vocab[word]\n",
    "            i += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432682/432682 [01:00<00:00, 7110.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 18.68% of vocab\n",
      "Found embeddings for  79.65% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def text_cleaning(text):\n",
    "    #STOPWORDS = set(stopwords.words('english'))\n",
    "    '''Turn the text into all lowercase, remove brackets, \n",
    "    punctuation, and numbers, and removing stopwords'''\n",
    "    #text = text.lower()\n",
    "    #text = re.sub('[/(){}\\[\\]\\|@,;?!\\.$]', '', text)\n",
    "    #text = re.sub('[^0-9a-z #+_]', '', text)\n",
    "    #text = re.sub('[&]', ' & ')\n",
    "    #text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    #combine_whitespace = re.compile(r\"\\s+\")\n",
    "    #text = combine_whitespace.sub(\" \", text).strip()\n",
    "    #text = ' '.join(text.split())\n",
    "\n",
    "\n",
    "    #text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 597874/597874 [10:23<00:00, 959.50it/s] \n"
     ]
    }
   ],
   "source": [
    "df['new'] = df['narrative'].progress_apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 597874/597874 [00:11<00:00, 52504.60it/s] \n"
     ]
    }
   ],
   "source": [
    "df['new'] = df['new'].progress_apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 597874/597874 [06:00<00:00, 1658.31it/s] \n",
      "100%|██████████| 597874/597874 [02:34<00:00, 3862.31it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = df['new'].progress_apply(lambda x: str(x).split())\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in \"/-'\":\n",
    "        x = x.replace(punct, ' ')\n",
    "    for punct in '&':\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n",
    "        x = x.replace(punct, '')\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 597874/597874 [02:33<00:00, 3903.61it/s]\n",
      "100%|██████████| 597874/597874 [10:16<00:00, 969.02it/s]  \n",
      "100%|██████████| 597874/597874 [03:34<00:00, 2783.98it/s]\n"
     ]
    }
   ],
   "source": [
    "df['new'] = df['narrative'].progress_apply(clean_text)\n",
    "sentences = df['new'].progress_apply(lambda x: str(x).split())\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'transworld': 69, 'systems': 4072, 'inc': 857, 'is': 1063715, 'trying': 67432, 'to': 3787094, 'collect': 40642, 'a': 2189136, 'debt': 290977, 'that': 1735365}\n"
     ]
    }
   ],
   "source": [
    "print({k: vocab[k] for k in list(vocab)[:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211466/211466 [00:44<00:00, 4776.76it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 39.93% of vocab\n",
      "Found embeddings for  90.09% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 3787094),\n",
       " ('and', 3041890),\n",
       " ('a', 2189136),\n",
       " ('of', 1954694),\n",
       " ('Navient', 30851),\n",
       " ('didnt', 16591),\n",
       " ('cancelled', 14898),\n",
       " ('judgement', 6798),\n",
       " ('wasnt', 5783),\n",
       " ('equifax', 5339),\n",
       " ('Shellpoint', 5154),\n",
       " ('Coinbase', 5021),\n",
       " ('experian', 4326),\n",
       " ('Seterus', 4207),\n",
       " ('EXPERIAN', 4191),\n",
       " ('COVID', 4035),\n",
       " ('doesnt', 3976),\n",
       " ('transunion', 3589),\n",
       " ('PSLF', 3147),\n",
       " ('Comenity', 3140),\n",
       " ('VALIDATION', 3108),\n",
       " ('FedLoan', 2914),\n",
       " ('onXX', 2898),\n",
       " ('BUREAUS', 2670),\n",
       " ('isnt', 2588),\n",
       " ('XXXXI', 2568),\n",
       " ('TRANSUNION', 2559),\n",
       " ('Covid', 2128),\n",
       " ('Loancare', 2123),\n",
       " ('acknowledgement', 1978),\n",
       " ('LVNV', 1922),\n",
       " ('tradeline', 1880),\n",
       " ('XXXXand', 1753),\n",
       " ('cfpb', 1691),\n",
       " ('XXXX####', 1533),\n",
       " ('navient', 1423),\n",
       " ('XXXXDispute', 1314),\n",
       " ('XXXX##', 1302),\n",
       " ('cancelling', 1257),\n",
       " ('coinbase', 1253),\n",
       " ('Fedloan', 1228),\n",
       " ('OnXX', 1226),\n",
       " ('QWR', 1224),\n",
       " ('shouldnt', 1171),\n",
       " ('VERIFIABLE', 1170),\n",
       " ('covid', 1167),\n",
       " ('NAVIENT', 1166),\n",
       " ('Inquired', 1155),\n",
       " ('NewRez', 1143),\n",
       " ('DEPTEDXXXX', 1123),\n",
       " ('Dovenmuehle', 1087),\n",
       " ('tradelines', 1060),\n",
       " ('inXX', 1043),\n",
       " ('learnmore', 1033),\n",
       " ('NationStar', 1004),\n",
       " ('DEROGATORY', 998),\n",
       " ('VALIDITY', 875),\n",
       " ('fcra', 849),\n",
       " ('Netspend', 842),\n",
       " ('hasnt', 836),\n",
       " ('SYNCB', 824),\n",
       " ('Amerihome', 811),\n",
       " ('EDXXXX', 787),\n",
       " ('elsewise', 786),\n",
       " ('UNVERIFIED', 781),\n",
       " ('COMPLIANCES', 779),\n",
       " ('DateXX', 777),\n",
       " ('CERTIFIABLE', 762),\n",
       " ('INACCURATELY', 728),\n",
       " ('chrc', 725),\n",
       " ('wwwconsumerfinancegov', 724),\n",
       " ('REPAYE', 655),\n",
       " ('ocwen', 635),\n",
       " ('Frauding', 629),\n",
       " ('Statebridge', 626),\n",
       " ('VALIDATED', 626),\n",
       " ('DiTech', 616),\n",
       " ('NATIONSTAR', 597),\n",
       " ('XXXXThe', 596),\n",
       " ('DESIST', 592),\n",
       " ('DELETION', 590),\n",
       " ('judgements', 583),\n",
       " ('Reptg', 573),\n",
       " ('1XXXX', 565),\n",
       " ('Reinvestigation', 563),\n",
       " ('UDAAP', 557),\n",
       " ('l1S', 550),\n",
       " ('ditech', 547),\n",
       " ('bitcoin', 545),\n",
       " ('##USC', 526),\n",
       " ('FRAUDULENTLY', 511),\n",
       " ('Wellsfargo', 511),\n",
       " ('NOTIFICATIONS', 507),\n",
       " ('##XXXX', 505),\n",
       " ('consumerfinancegov', 505),\n",
       " ('OpenedXX', 494),\n",
       " ('CFBP', 494),\n",
       " ('DIDNT', 493),\n",
       " ('Bridgecrest', 490),\n",
       " ('FURNISHERS', 478)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\n",
      "in\n",
      "for\n",
      "that\n",
      "is\n",
      "on\n",
      "##\n",
      "The\n",
      "with\n",
      "said\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(embeddings_index.index2entity[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_numbers(x):\n",
    "\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 597874/597874 [02:23<00:00, 4180.05it/s]\n",
      "  9%|▊         | 51021/597874 [00:02<00:27, 19997.00it/s]"
     ]
    }
   ],
   "source": [
    "df['new'] = df['new'].progress_apply(lambda x: clean_numbers(x))\n",
    "sentences = df['new'].progress_apply(lambda x: str(x).split())\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "\n",
    "mispell_dict = {'didnt':'did not',\n",
    "                'doesnt':'does not',\n",
    "                'isnt':'is not',\n",
    "                'shouldnt':'should not',\n",
    "                'wasnt':'was not',\n",
    "                'judgement':'judgment',\n",
    "                'isnt': 'is not',\n",
    "                'cancelled':'canceled',\n",
    "                'cancelling':'canceling',\n",
    "                'hasnt':'has not',\n",
    "                'dont':'do not'\n",
    "                }\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    \n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 597874/597874 [00:37<00:00, 15951.60it/s]\n"
     ]
    }
   ],
   "source": [
    "df['new'] = df['new'].progress_apply(replace_typical_misspell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 597874/597874 [13:44<00:00, 725.53it/s]   \n",
      "100%|██████████| 597874/597874 [03:55<00:00, 2539.30it/s]\n",
      "100%|██████████| 597874/597874 [03:22<00:00, 2951.30it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = df['new'].progress_apply(lambda x: str(x).split())\n",
    "to_remove = ['a','to','of','and']\n",
    "sentences = [[word for word in sentence if not word in to_remove] for sentence in tqdm(sentences)]\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211433/211433 [00:41<00:00, 5126.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 39.93% of vocab\n",
      "Found embeddings for  99.49% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157740/157740 [00:19<00:00, 7933.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 32.33% of vocab\n",
      "Found embeddings for  99.01% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'new_complaints3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>narrative</th>\n",
       "      <th>Product</th>\n",
       "      <th>word_count</th>\n",
       "      <th>new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transworld systems inc. \\nis trying to collect...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>18</td>\n",
       "      <td>transworld systems inc \\nis trying to collect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Over the past 2 weeks, I have been receiving e...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>78</td>\n",
       "      <td>Over the past 2 weeks I have been receiving ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pioneer has committed several federal violatio...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>152</td>\n",
       "      <td>Pioneer has committed several federal violatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Previously, on XX/XX/XXXX, XX/XX/XXXX, and XX/...</td>\n",
       "      <td>Credit or consumer reporting, credit repair se...</td>\n",
       "      <td>171</td>\n",
       "      <td>Previously on XX XX XXXX XX XX XXXX and XX XX ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hello This complaint is against the three cred...</td>\n",
       "      <td>Credit or consumer reporting, credit repair se...</td>\n",
       "      <td>428</td>\n",
       "      <td>Hello This complaint is against the three cred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823676</th>\n",
       "      <td>1 : Mailing Address is incorrect. \\n2 : Date o...</td>\n",
       "      <td>Personal loan</td>\n",
       "      <td>19</td>\n",
       "      <td>1  Mailing Address is incorrect \\n2  Date of B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823677</th>\n",
       "      <td>I made a purchase of {$500.00} on XXXX XXXX, 2...</td>\n",
       "      <td>Credit card or prepaid card</td>\n",
       "      <td>44</td>\n",
       "      <td>I made a purchase of ##### on XXXX XXXX #### u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823680</th>\n",
       "      <td>On XXXX XXXX, 2015, I contacted XXXX XXXX, who...</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>331</td>\n",
       "      <td>On XXXX XXXX #### I contacted XXXX XXXX who is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823681</th>\n",
       "      <td>I can not get from chase who services my mortg...</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>21</td>\n",
       "      <td>I can not get from chase who services my mortg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823682</th>\n",
       "      <td>cfbp i would Like to file a complaint on Exper...</td>\n",
       "      <td>Credit or consumer reporting, credit repair se...</td>\n",
       "      <td>150</td>\n",
       "      <td>cfbp i would Like to file a complaint on Exper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597874 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 narrative  \\\n",
       "1        transworld systems inc. \\nis trying to collect...   \n",
       "3        Over the past 2 weeks, I have been receiving e...   \n",
       "6        Pioneer has committed several federal violatio...   \n",
       "8        Previously, on XX/XX/XXXX, XX/XX/XXXX, and XX/...   \n",
       "9        Hello This complaint is against the three cred...   \n",
       "...                                                    ...   \n",
       "1823676  1 : Mailing Address is incorrect. \\n2 : Date o...   \n",
       "1823677  I made a purchase of {$500.00} on XXXX XXXX, 2...   \n",
       "1823680  On XXXX XXXX, 2015, I contacted XXXX XXXX, who...   \n",
       "1823681  I can not get from chase who services my mortg...   \n",
       "1823682  cfbp i would Like to file a complaint on Exper...   \n",
       "\n",
       "                                                   Product  word_count  \\\n",
       "1                                          Debt collection          18   \n",
       "3                                          Debt collection          78   \n",
       "6                                          Debt collection         152   \n",
       "8        Credit or consumer reporting, credit repair se...         171   \n",
       "9        Credit or consumer reporting, credit repair se...         428   \n",
       "...                                                    ...         ...   \n",
       "1823676                                      Personal loan          19   \n",
       "1823677                        Credit card or prepaid card          44   \n",
       "1823680                                           Mortgage         331   \n",
       "1823681                                           Mortgage          21   \n",
       "1823682  Credit or consumer reporting, credit repair se...         150   \n",
       "\n",
       "                                                       new  \n",
       "1        transworld systems inc \\nis trying to collect ...  \n",
       "3        Over the past 2 weeks I have been receiving ex...  \n",
       "6        Pioneer has committed several federal violatio...  \n",
       "8        Previously on XX XX XXXX XX XX XXXX and XX XX ...  \n",
       "9        Hello This complaint is against the three cred...  \n",
       "...                                                    ...  \n",
       "1823676  1  Mailing Address is incorrect \\n2  Date of B...  \n",
       "1823677  I made a purchase of ##### on XXXX XXXX #### u...  \n",
       "1823680  On XXXX XXXX #### I contacted XXXX XXXX who is...  \n",
       "1823681  I can not get from chase who services my mortg...  \n",
       "1823682  cfbp i would Like to file a complaint on Exper...  \n",
       "\n",
       "[597874 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Navient', 30851),\n",
       " ('equifax', 5339),\n",
       " ('Shellpoint', 5154),\n",
       " ('Coinbase', 5021),\n",
       " ('experian', 4326),\n",
       " ('Seterus', 4207),\n",
       " ('EXPERIAN', 4191),\n",
       " ('COVID', 4035),\n",
       " ('transunion', 3589),\n",
       " ('PSLF', 3147),\n",
       " ('Comenity', 3140),\n",
       " ('VALIDATION', 3108),\n",
       " ('FedLoan', 2914),\n",
       " ('onXX', 2898),\n",
       " ('BUREAUS', 2670),\n",
       " ('XXXXI', 2568),\n",
       " ('TRANSUNION', 2559),\n",
       " ('Covid', 2128),\n",
       " ('Loancare', 2123),\n",
       " ('acknowledgement', 1978),\n",
       " ('LVNV', 1922),\n",
       " ('tradeline', 1880),\n",
       " ('XXXXand', 1753),\n",
       " ('cfpb', 1691),\n",
       " ('XXXX####', 1533),\n",
       " ('navient', 1423),\n",
       " ('XXXXDispute', 1314),\n",
       " ('XXXX##', 1302),\n",
       " ('coinbase', 1253),\n",
       " ('Fedloan', 1228),\n",
       " ('OnXX', 1226),\n",
       " ('QWR', 1224),\n",
       " ('VERIFIABLE', 1170),\n",
       " ('covid', 1167),\n",
       " ('NAVIENT', 1166),\n",
       " ('Inquired', 1155),\n",
       " ('NewRez', 1143),\n",
       " ('DEPTEDXXXX', 1123),\n",
       " ('Dovenmuehle', 1087),\n",
       " ('tradelines', 1060),\n",
       " ('inXX', 1043),\n",
       " ('learnmore', 1033),\n",
       " ('NationStar', 1004),\n",
       " ('DEROGATORY', 998),\n",
       " ('VALIDITY', 875),\n",
       " ('fcra', 849),\n",
       " ('Netspend', 842),\n",
       " ('SYNCB', 824),\n",
       " ('Amerihome', 811),\n",
       " ('EDXXXX', 787),\n",
       " ('elsewise', 786),\n",
       " ('UNVERIFIED', 781),\n",
       " ('COMPLIANCES', 779),\n",
       " ('DateXX', 777),\n",
       " ('CERTIFIABLE', 762),\n",
       " ('INACCURATELY', 728),\n",
       " ('chrc', 725),\n",
       " ('wwwconsumerfinancegov', 724),\n",
       " ('REPAYE', 655),\n",
       " ('ocwen', 635),\n",
       " ('Frauding', 629),\n",
       " ('Statebridge', 626),\n",
       " ('VALIDATED', 626),\n",
       " ('DiTech', 616),\n",
       " ('NATIONSTAR', 597),\n",
       " ('XXXXThe', 596),\n",
       " ('DESIST', 592),\n",
       " ('DELETION', 590),\n",
       " ('Reptg', 573),\n",
       " ('1XXXX', 565),\n",
       " ('Reinvestigation', 563),\n",
       " ('UDAAP', 557),\n",
       " ('l1S', 550),\n",
       " ('ditech', 547),\n",
       " ('bitcoin', 545),\n",
       " ('##USC', 526),\n",
       " ('FRAUDULENTLY', 511),\n",
       " ('Wellsfargo', 511),\n",
       " ('NOTIFICATIONS', 507),\n",
       " ('##XXXX', 505),\n",
       " ('consumerfinancegov', 505),\n",
       " ('OpenedXX', 494),\n",
       " ('CFBP', 494),\n",
       " ('DIDNT', 493),\n",
       " ('Bridgecrest', 490),\n",
       " ('FURNISHERS', 478),\n",
       " ('INQUIRES', 477),\n",
       " ('REINVESTIGATION', 470),\n",
       " ('3XXXX', 468),\n",
       " ('fromXX', 465),\n",
       " ('2XXXX', 459),\n",
       " ('DOFD', 450),\n",
       " ('XXXXto', 431),\n",
       " ('Furnisher', 427),\n",
       " ('ProCollect', 425),\n",
       " ('NELNET', 421),\n",
       " ('XXXXThis', 416),\n",
       " ('ofXX', 416),\n",
       " ('Citicards', 403),\n",
       " ('meI', 402)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
